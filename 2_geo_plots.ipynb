{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab0c0e6c-42ad-4862-bdbf-04384bf7fe97",
   "metadata": {},
   "source": [
    "# 1_geo_plots\n",
    "\n",
    "Creatining maps\n",
    "\n",
    "01/15/2024\n",
    "\n",
    "update 10/03/24\n",
    "remade plots on 04/04/25\n",
    "making geoplots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0610e5f8-3bf4-43ee-aabd-1a9052d6ba07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "import pickle\n",
    "import plotly.express as px\n",
    "import plotly.offline as py_offline\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "from folium.plugins import HeatMap\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from collections import defaultdict, Counter\n",
    "import censusdata\n",
    "import json\n",
    "# !pip install censusdata\n",
    "from urllib.request import urlopen\n",
    "import json\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry import shape  # Import the shape function\n",
    "import branca\n",
    "import branca.colormap as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "df343843-f53f-4663-b65b-1135cd653ade",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_prefix = 'geoplots/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5da2177a-09f3-4488-9ffd-411439c6d40c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.1 s, sys: 3.61 s, total: 28.7 s\n",
      "Wall time: 28.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "active_trials = json.load(open('interventional_trials_with_descendants2024-07-26.json','r'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c269ca8c-44dc-4c60-99e4-eebe59cf5034",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20894, 20894)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(active_trials['data']), active_trials['total']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "63fe8050-fac2-4b2b-b0b1-1ced7f47f7ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "biomarker_trials = []\n",
    "nonbiomarker_trials = []\n",
    "years_arr = []\n",
    "\n",
    "for study in active_trials['data']:\n",
    "    genes = [g for g in study['biomarkers_new']['inclusion']['TREE']['symbols_dz'] if type(g)==str]\n",
    "    if len(genes) >0:\n",
    "        biomarker_trials.append(study)\n",
    "        year = study['start_date'].split('-')[0]\n",
    "        years_arr.append(year)\n",
    "    else:\n",
    "        nonbiomarker_trials.append(study)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "16b8a55d-e0fd-4425-a8be-32f5e0866edc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5057, 15837)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(biomarker_trials),len(nonbiomarker_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4b6438ff-6372-4346-a581-10ec5ef634de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'2021': 495,\n",
       "         '2018': 478,\n",
       "         '2020': 477,\n",
       "         '2019': 467,\n",
       "         '2017': 462,\n",
       "         '2022': 428,\n",
       "         '2023': 425,\n",
       "         '2016': 371,\n",
       "         '2015': 360,\n",
       "         '2014': 297,\n",
       "         '2024': 285,\n",
       "         '2013': 196,\n",
       "         '2012': 123,\n",
       "         '2011': 69,\n",
       "         '2010': 46,\n",
       "         '2009': 31,\n",
       "         '2008': 14,\n",
       "         '2007': 11,\n",
       "         '2006': 9,\n",
       "         '2025': 7,\n",
       "         '2005': 2,\n",
       "         '2001': 1,\n",
       "         '2004': 1,\n",
       "         '1993': 1,\n",
       "         '2003': 1})"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(years_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f5e27702-248b-46df-a631-9323f6d0c7e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test = biomarker_trials[0]\n",
    "# test['sites']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dce38e4-9dbe-4d4c-9ecf-09c526a02bfb",
   "metadata": {},
   "source": [
    "# 1. plot functions\n",
    "(code from travis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bf579e96-7993-485f-b1c9-c980b0271e58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_circle_map(study_list, savefile):\n",
    "    \"\"\"\n",
    "    study_list <list>\n",
    "    savefile: <str> i.e \"../figures/appendix_circle_map.html\"\n",
    "    return: coordinates_count <dict> \n",
    "    \"\"\"\n",
    "    # make a map with circles for size \n",
    "    map_usa = folium.Map(location=[37.0902, -95.7129], zoom_start=4,control=True)\n",
    "\n",
    "    # Count occurrences of coordinates\n",
    "    coordinates_count = {}\n",
    "    coord_list = list()\n",
    "    for trial in study_list:\n",
    "        for site in trial[\"sites\"]:\n",
    "            if site[\"org_coordinates\"] is not None:\n",
    "                coord = (site[\"org_coordinates\"][\"lat\"], site[\"org_coordinates\"][\"lon\"])\n",
    "                coord_list.append(coord)\n",
    "                coordinates_count[coord] = coordinates_count.get(coord, 0) + 1\n",
    "\n",
    "    # Plot circles\n",
    "    for coord, count in coordinates_count.items():\n",
    "        folium.CircleMarker(\n",
    "            location=coord,\n",
    "            radius=np.log(count) ,  # Adjust size to your preference\n",
    "            color='blue',\n",
    "            fill=True,\n",
    "            fill_color='blue'\n",
    "        ).add_to(map_usa)\n",
    "\n",
    "    \n",
    "    # Save or display the map\n",
    "    map_usa.save(savefile)\n",
    "    \n",
    "    return coordinates_count\n",
    "\n",
    "\n",
    "def create_cluster_map(coordinates_count, savefile, radius=60):\n",
    "    \"\"\"\n",
    "    clustering the initialy circle map more by location \n",
    "    \n",
    "    coordinates_count: <dict>\n",
    "    savefile <str> ie,    \"../figures/appendix_map_cluster.html\"\n",
    "    radius <int> \n",
    "    \n",
    "    return None\n",
    "    \n",
    "    \"\"\"\n",
    "    map_usa = folium.Map(location=[37.0902, -95.7129], zoom_start=4)\n",
    "    marker_cluster = MarkerCluster(maxClusterRadius=radius).add_to(map_usa)  # Adjust the radius as needed\n",
    "\n",
    "    # Add points to the cluster\n",
    "    for coord, count in coordinates_count.items():\n",
    "        folium.Marker(\n",
    "            location=coord,\n",
    "            popup=f'Count: {count}',\n",
    "            icon=None\n",
    "        ).add_to(marker_cluster)\n",
    "\n",
    "    # Save or display the map\n",
    "    map_usa.save(savefile)\n",
    "\n",
    "\n",
    "# Function to create slightly offset points\n",
    "def create_offset_points(coord, count):\n",
    "    lat, lon = coord\n",
    "    offset = 0.001  # Small offset value\n",
    "    return [(lat + offset, lon, count // 2), (lat - offset, lon, count // 2)]\n",
    "\n",
    "def create_cluster_offset_map(coordinates_count, savefile):\n",
    "    \"\"\"\n",
    "    circles on map but more grouped and using offset points\n",
    "    \n",
    "    study_list <list>\n",
    "    savefile: <str> i.e. \"../figures/appendix_map_cluster_updated.html\"\n",
    "    return: new_coordinates_count <dict> \n",
    "    \"\"\"    \n",
    "    # Original map setup\n",
    "    map_usa = folium.Map(location=[37.0902, -95.7129], zoom_start=4)\n",
    "    marker_cluster = MarkerCluster(maxClusterRadius=40).add_to(map_usa)\n",
    "\n",
    "    # Updated data processing\n",
    "    new_coordinates_count = {}\n",
    "    for coord, count in coordinates_count.items():\n",
    "        #if count == 1:\n",
    "            # Split individual points into two offset points\n",
    "        for new_coord in create_offset_points(coord, count):\n",
    "            new_coordinates_count[new_coord[:2]] = new_coord[2]\n",
    "        #else:\n",
    "        #    new_coordinates_count[coord] = count\n",
    "\n",
    "    # Add the updated points to the cluster\n",
    "    for coord, count in new_coordinates_count.items():\n",
    "        folium.Marker(\n",
    "            location=coord,\n",
    "            popup=f'Count: {count}',\n",
    "            icon=None\n",
    "        ).add_to(marker_cluster)\n",
    "\n",
    "    # Save or display the map\n",
    "    map_usa.save(savefile)\n",
    "    \n",
    "    return new_coordinates_count\n",
    "\n",
    "def create_heatmap(coordinates_count, savefile,radius=20,blur=15, steps=100,max_zoom=1,\n",
    "                  colors_arr=['red', 'orange', 'yellow', 'green', 'cyan',\n",
    "                                        'blue','indigo','black']):\n",
    "    \"\"\"\n",
    "    heat overlaying map, the heatmap is just looks like fuzzy paint colors on the country\n",
    "    \n",
    "    colors_arr=['red', 'orange', 'yellow', 'green', \n",
    "                                        'blue', 'indigo', 'violet','black']\n",
    "                                        \n",
    "    study_list <list>\n",
    "    savefile: <str> i.e. \"../figures/appendix_map_cluster_updated.html\"\n",
    "    return: None\n",
    "    \"\"\"  \n",
    "    \n",
    "    map_usa = folium.Map(location=[37.0902, -95.7129], zoom_start=4)\n",
    "\n",
    "    # Prepare data for HeatMap\n",
    "    heat_data = [[coord[0], coord[1], count] for coord, count in coordinates_count.items()]\n",
    "\n",
    "    # create gradient\n",
    "    color_map=cm.LinearColormap(colors=colors_arr[::-1]).to_step(steps)\n",
    "    \n",
    "    color_map.caption = \"Relative Density of Clinical Trials\"  # how do I change fontsize and color here?\n",
    "    map_usa.add_child(color_map)\n",
    "\n",
    "    gradient_map=defaultdict(dict)\n",
    "    for i in range(steps):\n",
    "        gradient_map[1/steps*i] = color_map.rgb_hex_str(1/steps*i)\n",
    "\n",
    "\n",
    "    # Create a HeatMap with customized parameters\n",
    "    HeatMap(heat_data, gradient = gradient_map, radius=radius, blur=blur, max_zoom=max_zoom).add_to(map_usa)\n",
    "\n",
    "    # Save or display the map\n",
    "    map_usa.save(savefile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303eeb1d-71d4-4d95-aa33-94ecaccc734a",
   "metadata": {},
   "source": [
    "# 2.  make per county heatmap and dot plot maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1f635b2b-0ffb-404c-996e-54cf92783284",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 181 ms, sys: 15.6 ms, total: 197 ms\n",
      "Wall time: 533 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# getting counties\n",
    "with urlopen('https://raw.githubusercontent.com/plotly/datasets/master/geojson-counties-fips.json') as response:\n",
    "    counties = json.load(response)\n",
    "\n",
    "# Assuming counties is your GeoJSON data\n",
    "gdf_counties = gpd.GeoDataFrame.from_features(counties['features'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9577be3a-7b6b-4541-917f-34766bbd23f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262910\n",
      "CPU times: user 227 ms, sys: 233 ms, total: 460 ms\n",
      "Wall time: 459 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "coord_list = list()\n",
    "coord_list_phase1 = list()\n",
    "coord_list_phase2 = list()\n",
    "coord_list_phase3 = list()\n",
    "coord_list_phase4 = list()\n",
    "\n",
    "org_to_coord = defaultdict(set)\n",
    "coord_to_org = defaultdict(set)\n",
    "\n",
    "for trial in active_trials['data']:\n",
    "\n",
    "    for site in trial[\"sites\"]:\n",
    "        \n",
    "        \n",
    "        if site[\"org_coordinates\"] is not None:\n",
    "            coord = (site[\"org_coordinates\"][\"lat\"], site[\"org_coordinates\"][\"lon\"])\n",
    "            coord_list.append(coord)\n",
    "            org_to_coord[site['org_name']].add(coord)\n",
    "            coord_to_org[coord].add(site['org_name'])\n",
    "\n",
    "            if trial['phase']=='I':\n",
    "                coord_list_phase1.append(coord)\n",
    "            elif trial['phase']=='II' or trial['phase']=='I_II':\n",
    "                coord_list_phase2.append(coord)\n",
    "            elif trial['phase']=='III'or trial['phase'] =='II_III':\n",
    "                coord_list_phase3.append(coord)\n",
    "            elif trial['phase']=='IV':\n",
    "                coord_list_phase4.append(coord)\n",
    "\n",
    "print(len(coord_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "98fba3bc-fbe5-4418-8ec9-9e152049d473",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262910 3221\n",
      "CPU times: user 1.19 s, sys: 13.6 ms, total: 1.2 s\n",
      "Wall time: 1.22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# initializing data\n",
    "\n",
    "# Convert your coordinate tuples to Shapely Points and then to a GeoDataFrame\n",
    "gdf_points = gpd.GeoDataFrame(geometry=[Point(lon, lat) for lat, lon in coord_list])\n",
    "\n",
    "# Set the same coordinate reference system as the counties GeoDataFrame\n",
    "gdf_points.crs = gdf_counties.crs\n",
    "\n",
    "# Initialize a dictionary to hold the count of points in each county\n",
    "county_point_count = {feature['properties']['NAME']: 0 for feature in counties['features']}\n",
    "\n",
    "print(len(gdf_points.geometry), len(counties['features']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6ed04058-448a-4b08-8d55-80b1cbda332d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2230"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "point_to_count = gdf_points.geometry.value_counts().to_dict()\n",
    "len(point_to_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c1b1f860-9138-4375-9357-a3257d959ccc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 11s, sys: 1.39 s, total: 2min 12s\n",
      "Wall time: 2min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#takes a bit\n",
    "\n",
    "# Check each point to see which county it falls into and increment the count\n",
    "for point,count in  point_to_count.items():\n",
    "    # if (idx%1000==0):\n",
    "    #     print(idx, 'of', len(gdf_points.geometry))\n",
    "    for feature in counties['features']:\n",
    "        polygon = shape(feature['geometry'])\n",
    "        if point.within(polygon):\n",
    "            county_name = feature['properties']['NAME']\n",
    "            county_point_count[county_name] += count\n",
    "            break\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9bd3c118-cb60-4970-a047-a2366986b136",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write pickle data\n",
    "with open('geoplots/all_group_interv_county_counts_intervention.pkl', 'wb') as file:\n",
    "    pickle.dump(county_point_count, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b4978ed8-6a25-46a3-ae3b-a32cb8cb2972",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 469 ms, sys: 21.6 ms, total: 491 ms\n",
      "Wall time: 506 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#plotting\n",
    "# Convert the county_point_count dictionary to a DataFrame\n",
    "# Assume 'county_fips' is a list of FIPS codes for each county\n",
    "county_fips = [feature['properties']['GEO_ID'] for feature in counties['features']]\n",
    "county_names = [feature['properties']['NAME'] for feature in counties['features']]\n",
    "county_area = [feature['properties']['CENSUSAREA'] for feature in counties['features']]\n",
    "df_count = pd.DataFrame({\n",
    "    'fips': county_fips,\n",
    "    'county_name': county_names,\n",
    "    'county_area': county_area,\n",
    "    'point_count': [county_point_count[name] for name in county_names]\n",
    "})\n",
    "\n",
    "# Adjust point_count for logarithmic scale (adding 1 to avoid log(0)) scaled by county area\n",
    "df_count['log_point_count'] = df_count['point_count'].apply(lambda x: np.log10(x + 1))\n",
    "\n",
    "df_count['log_point_count_scale'] = df_count.apply(lambda row: min(.01,row['log_point_count']/row['county_area']),axis=1)\n",
    "                                                        \n",
    "\n",
    "# Plot the choropleth map using the logarithmically scaled data\n",
    "fig = px.choropleth(df_count, geojson=counties, locations='fips', color='log_point_count_scale',\n",
    "                    color_continuous_scale=\"Viridis\",\n",
    "                    range_color=(0, max(df_count['log_point_count_scale'])),\n",
    "                    scope=\"usa\",\n",
    "                    featureidkey=\"properties.GEO_ID\",\n",
    "                    labels={'log_point_count_scale':'Logarithmic Point Count (scaled by county size) '}\n",
    "                   )\n",
    "fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "fig.update_layout(\n",
    "    coloraxis_colorbar_title_font_size=16,  # Adjust the title font size\n",
    "    coloraxis_colorbar_tickfont_size=14     # Adjust the tick labels font size\n",
    ")\n",
    "fig.write_html(\"geoplots/all_group_interv_choropleth_map_log_scale_by_size.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9eaebb2e-8d05-4770-98d5-763d4fd666cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "coordinates_count = create_circle_map(active_trials['data'], os.path.join(save_prefix,'all_group_map_circle.html'))\n",
    "create_heatmap(coordinates_count,  os.path.join(save_prefix,'all_group_map_heatmap.html'),radius=5,blur=1,max_zoom=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "034c8309-49ae-42e9-934b-6c25eeacf344",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "coordinates_count = create_circle_map(biomarker_trials, os.path.join(save_prefix,'biomarkers_group_map_circle.html'))\n",
    "create_heatmap(coordinates_count,  os.path.join(save_prefix,'biomarkers_group_map_heatmap.html'),radius=5,blur=1,max_zoom=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a977ffa5-62ff-4048-a97e-e0f64611649e",
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates_count = create_circle_map(nonbiomarker_trials, os.path.join(save_prefix,'nonbiomarkers_group_map_circle.html'))\n",
    "create_heatmap(coordinates_count,  os.path.join(save_prefix,'nonbiomarkers_group_map_heatmap.html'),radius=5,blur=1,max_zoom=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc6005b-ff8a-4e4e-94ca-4cd3421bb2c1",
   "metadata": {},
   "source": [
    "# Part 3 - figure out if coordinate is urban or not\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "298d3082-0135-484a-83c0-0c2adbf2437a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shapefile\n",
    "import geopandas as gpd\n",
    "shp = shapefile.Reader('geoplots/tl_rd22_us_uac20/tl_rd22_us_uac20.shp') #open the shapefile\n",
    "all_shapes = shp.shapes() # get all the polygons\n",
    "all_records = shp.records()\n",
    "polygons_gpd = gpd.GeoDataFrame(geometry=all_shapes) #convert the polygons into a geodataframe\n",
    "\n",
    "def is_urban(coord):\n",
    "    #test chicago IL: (41.878,-87.6298)\n",
    "    # result = False\n",
    "    lat,long = coord\n",
    "    points_gpd = gpd.GeoDataFrame(geometry=gpd.points_from_xy([long], [lat]))  # point coordinates to geopandas dataframe\n",
    "    pt2poly = gpd.sjoin(points_gpd,polygons_gpd, predicate='within').index_right  # for each point index in the points, it stores the polygon index containing that point\n",
    "    if len(pt2poly) >= 1:  # if any indicies are found, it's urban\n",
    "        return True\n",
    "    else:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "30e42020-e553-4e3a-ac4f-34a94f01b7b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.5 s, sys: 153 ms, total: 14.6 s\n",
      "Wall time: 14.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "urban_coords = []\n",
    "counter_phaseall_urban = 0\n",
    "\n",
    "for coord,count_trials  in Counter(coord_list).items():\n",
    "    if is_urban(coord):\n",
    "        urban_coords.append(coord)\n",
    "        counter_phaseall_urban+=count_trials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4468c14d-5a5b-444e-9705-bfa341d947cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2230"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Counter(coord_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "525d37df-1f79-4e69-927a-e88707416a1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20894"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(active_trials['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6689471b-0846-411b-90db-6c64b9c64253",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29.7059, -95.4026) 5448 True\n",
      "(42.3469, -71.1025) 3473 True\n",
      "(40.7656, -73.9624) 2976 True\n",
      "(38.6267, -90.267) 2395 True\n",
      "(41.5063, -81.6065) 1894 True\n",
      "(42.341, -71.0948) 1881 True\n",
      "(33.792, -84.3239) 1840 True\n",
      "(34.1357, -117.9655) 1836 True\n",
      "(42.3621, -71.068) 1823 True\n",
      "(47.6307, -122.3461) 1823 True\n",
      "4276 20894 0.2046520532210204 in top 10 sites\n"
     ]
    }
   ],
   "source": [
    "# , with XXX occurring only within one of the top 10 sites. \n",
    "coord_to_numtrials = Counter(coord_list)\n",
    "coord_to_numtrials_sorted_keys = sorted(coord_to_numtrials, key=coord_to_numtrials.get, reverse=True)\n",
    "\n",
    "#only want top 10 sites\n",
    "idx = 0\n",
    "top10_coordlist = []\n",
    "for coord in coord_to_numtrials_sorted_keys:\n",
    "    if idx > 9:\n",
    "        break\n",
    "    print(coord, coord_to_numtrials[coord],is_urban(coord))\n",
    "    top10_coordlist.append(coord)\n",
    "    idx+=1\n",
    "    \n",
    "# find out how many trials occur at these areas:\n",
    "counter_trial = 0\n",
    "for trial in active_trials['data']:\n",
    "    trial_intop10 = []\n",
    "    for site in trial[\"sites\"]:\n",
    "        if site[\"org_coordinates\"] is not None:\n",
    "            coord = (site[\"org_coordinates\"][\"lat\"], site[\"org_coordinates\"][\"lon\"])\n",
    "            if coord in top10_coordlist:\n",
    "                trial_intop10.append(True)\n",
    "            else:\n",
    "                trial_intop10.append(False)\n",
    "    \n",
    "    if all(trial_intop10):\n",
    "        counter_trial+=1\n",
    "                \n",
    "            \n",
    "print(counter_trial, len(active_trials['data']), \n",
    "      counter_trial/len(active_trials['data']),\n",
    "      'in top 10 sites')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73111ef-00b6-44a1-a6fc-a09ad8e83600",
   "metadata": {},
   "source": [
    "20.5% of trials occur only  in the 10 ten sites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef4582d-20b7-4b47-8972-14d285b48dea",
   "metadata": {},
   "source": [
    "by phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "dd166d5a-e296-4122-896b-a6c721993168",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.98 s, sys: 24.1 ms, total: 2.01 s\n",
      "Wall time: 2.01 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "counter_phase1_urban = 0\n",
    "counter_phase2_urban = 0\n",
    "counter_phase3_urban = 0\n",
    "counter_phase4_urban = 0\n",
    "\n",
    "counter_phaseall_urban = 0\n",
    "\n",
    "counter_phase1_all = 0\n",
    "counter_phase2_all = 0\n",
    "counter_phase3_all = 0\n",
    "counter_phase4_all = 0\n",
    "\n",
    "\n",
    "for trial in active_trials['data']:\n",
    "    trialsites_urban_boollist = []\n",
    "    for site in trial[\"sites\"]:\n",
    "        if site[\"org_coordinates\"] is not None:\n",
    "            coord = (site[\"org_coordinates\"][\"lat\"], site[\"org_coordinates\"][\"lon\"])\n",
    "            # coord_list.append(coord)\n",
    "            \n",
    "            if coord in urban_coords:\n",
    "                trialsites_urban_boollist.append(True)\n",
    "            else:\n",
    "                trialsites_urban_boollist.append(False)\n",
    "    \n",
    "    if trial['phase']=='I':\n",
    "        counter_phase1_all+=1\n",
    "    elif trial['phase']=='II' or trial['phase']=='I_II':\n",
    "        counter_phase2_all+=1\n",
    "    elif trial['phase']=='III'or trial['phase'] =='II_III':\n",
    "        counter_phase3_all+=1\n",
    "    elif trial['phase']=='IV':\n",
    "        counter_phase4_all+=1\n",
    "            \n",
    "    if all(trialsites_urban_boollist): # all trial locations are in urban areas:\n",
    "        counter_phaseall_urban+=1\n",
    "        #if at lease one of them is rurual \n",
    "        if trial['phase']=='I':\n",
    "            counter_phase1_urban+=1\n",
    "        elif trial['phase']=='II' or trial['phase']=='I_II':\n",
    "            counter_phase2_urban+=1\n",
    "        elif trial['phase']=='III'or trial['phase'] =='II_III':\n",
    "            counter_phase3_urban+=1\n",
    "        elif trial['phase']=='IV':\n",
    "            counter_phase4_urban+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "11c3cfad-8fe5-48de-983f-25501350c1d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall\n",
      "18934 20894 0.906193165502058\n",
      "phase I\n",
      "4888 5156 0.948021722265322\n",
      "phase II\n",
      "8150 9097 0.8958997471693965\n",
      "phase III\n",
      "1516 2036 0.7445972495088409\n",
      "phase 1V\n",
      "189 199 0.949748743718593\n"
     ]
    }
   ],
   "source": [
    "# print % urban\n",
    "print('overall')\n",
    "print(counter_phaseall_urban, len(active_trials['data']), counter_phaseall_urban/len(active_trials['data']))\n",
    "print('phase I')\n",
    "print(counter_phase1_urban, counter_phase1_all, counter_phase1_urban/counter_phase1_all)\n",
    "print('phase II')\n",
    "print(counter_phase2_urban, counter_phase2_all, counter_phase2_urban/counter_phase2_all)\n",
    "print('phase III')\n",
    "print(counter_phase3_urban, counter_phase3_all, counter_phase3_urban/counter_phase3_all)\n",
    "print('phase 1V')\n",
    "print(counter_phase4_urban, counter_phase4_all, counter_phase4_urban/counter_phase4_all)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670c3259-adfd-4d99-8ccb-3d852d9336b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9f9b6718-a7a2-4fac-b0c2-5a9824ad9561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1661"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(urban_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "76c5f432-eb6f-406c-8334-6250996353c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7448430493273542"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(urban_coords)/len(Counter(coord_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a84f4a-4fa0-4f76-8c0d-2291602cf466",
   "metadata": {},
   "source": [
    "There are only 2230 unique clinical trial sites (for the over 20,000 clinical trials). For these, only 1661 (or 74.4% of them) are located in urban areas, as defined by the 2020 US Census. As such 94.8% of phase I, 89.6% of phase II, and 74.4% of phase III clinical trials have sites that are solely in urban areas, which tend of cluster in areas. Given clinical trial access is often concentrated in urban areas, a nationwide, systematic approach is needed to ensure equitable access to clinical trials for all patients, regardless of their location."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
